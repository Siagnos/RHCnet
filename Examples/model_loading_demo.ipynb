{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow_addons.optimizers import RectifiedAdam\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../Utils')\n",
    "sys.path.append('../Models')\n",
    "\n",
    "from network_tools import *\n",
    "from hnet import *\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HemoNet: Model loading demonstration\n",
    "The notebook shows the simple procedure by which one can load, train, and do inference with HemoNet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and training HemoNet\n",
    "e.g. if you would like to start with our pre-trained model, then tune with your own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the pre-trained model\n",
    "PRE_TRAINED_MODEL_PATH = '../SavedModels/ecg_supervised_224.h5'\n",
    "\n",
    "# load it!\n",
    "pre_trained_model = load_model(PRE_TRAINED_MODEL_PATH, custom_objects={\n",
    "            'swish': tf.nn.swish,\n",
    "            'RectifiedAdam': RectifiedAdam,\n",
    "            'pearson': pearson,\n",
    "        })\n",
    "\n",
    "# take the model up to the latent layer, 224 nodes\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "\n",
    "# append the additional layers to the pre-trained layers which project to the latent space\n",
    "full_model = AppendNet(latent)\n",
    "full_model.build((None,5000,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## DATA ###########\n",
    "'''\n",
    "For the purposes of this demonstration, we generate random inputs and labels.\n",
    "The actual, pressure-matched training data will be de-identified released when\n",
    "possible.\n",
    "'''\n",
    "\n",
    "N = 100\n",
    "\n",
    "X_train = np.random.rand(N,5000,12)\n",
    "y_train = np.random.rand(N,4) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 313ms/step - loss: 0.8433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff6d853f490>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### TRAIN THE MODEL #####\n",
    "#   as much as you want   #\n",
    "#     or not at all       #\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam() # can modify LR, of course\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "epochs = 1\n",
    "\n",
    "'''\n",
    "Note: We wrote our own training loop so we could freely modify the procedure.\n",
    "Feel free to do so (https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)\n",
    "'''\n",
    "full_model.compile(optimizer, loss_fn)\n",
    "full_model.fit(X_train, y_train, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can do inference at will\n",
    "\n",
    "X_test = np.random.rand(100,5000,12)\n",
    "y_pred = full_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained HemoNet\n",
    "Here, we load the model that we had trained and used in our paper. All ten bootstraps are available.\n",
    "\n",
    "Due to an issue with tensorflow related to loading operations with custom gradents, we use our own function to load the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first, instantiate the model\n",
    "\n",
    "pre_trained_model = load_model(PRE_TRAINED_MODEL_PATH, custom_objects={\n",
    "            'swish': tf.nn.swish,\n",
    "            'RectifiedAdam': RectifiedAdam,\n",
    "            'pearson': pearson,\n",
    "        })\n",
    "\n",
    "# take the model up to the latent layer, 224 nodes\n",
    "latent = tf.keras.Model(pre_trained_model.inputs, pre_trained_model.get_layer('embed').output)\n",
    "\n",
    "# append the additional layers to the pre-trained layers which project to the latent space\n",
    "trained_model = AppendNet(latent)\n",
    "\n",
    "# load the weights\n",
    "trained_model = load_weights(trained_model,'../SavedModels/FinalBstraps/weights.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we get an output with shape Nx4, as desired\n",
    "N = 100\n",
    "random_out = trained_model.predict(np.random.rand(N,5000,12))\n",
    "random_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
